{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 3914,
     "status": "ok",
     "timestamp": 1678598822013,
     "user": {
      "displayName": "Piyaphat Pinyo",
      "userId": "18158885176219255666"
     },
     "user_tz": -420
    },
    "id": "_jm-sHTESPva"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "bCjSS0nKSkou"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1678598822016,
     "user": {
      "displayName": "Piyaphat Pinyo",
      "userId": "18158885176219255666"
     },
     "user_tz": -420
    },
    "id": "cSJholw5RKeI"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 224 # Image size of resize when applying transforms.\n",
    "BATCH_SIZE = 64\n",
    "NUM_WORKERS = 4 # Number of parallel processes for data preparation.\n",
    "SUBMISSION = 'submission.csv'\n",
    "DATA_DIR = 'test'\n",
    "MODEL_DIR = 'model.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dwzdDK6BTNCE"
   },
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "\n",
    "def build_model(pretrained=True, fine_tune=True, num_classes=11):\n",
    "    if pretrained:\n",
    "        print('[INFO]: Loading pre-trained weights')\n",
    "    else:\n",
    "        print('[INFO]: Not loading pre-trained weights')\n",
    "    model = models.efficientnet_b0(pretrained=pretrained)\n",
    "    if fine_tune:\n",
    "        print('[INFO]: Fine-tuning all layers...')\n",
    "        for params in model.parameters():\n",
    "            params.requires_grad = True\n",
    "    elif not fine_tune:\n",
    "        print('[INFO]: Freezing hidden layers...')\n",
    "        for params in model.parameters():\n",
    "            params.requires_grad = False\n",
    "            \n",
    "    num_features = model.classifier[-1].in_features\n",
    "    # Change the final classification head.\n",
    "    model.classifier[-1] = nn.Sequential(\n",
    "      nn.Dropout(p=0.5),\n",
    "      nn.Linear(num_features,num_classes),\n",
    "      nn.Softmax(dim=1) \n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "dYWKLU7ASAH5"
   },
   "outputs": [],
   "source": [
    "test_transform = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406],\n",
    "            std=[0.229, 0.224, 0.225]\n",
    "            )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "rF56ePVKT7T5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_names = os.listdir(root_dir)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.image_names[idx])\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        img_name = self.image_names[idx]\n",
    "        uid = int(img_name[len(\"test\"):img_name.find(\".\")])\n",
    "#         uid = int(img_name[:img_name.find(\".\")])\n",
    "        return image, uid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GFenQSHTSKdT"
   },
   "outputs": [],
   "source": [
    "dataset_test = CustomDataset(\n",
    "    DATA_DIR, \n",
    "    transform=test_transform\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "PSa-Fo_TR1T-"
   },
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "        dataset_test, batch_size=BATCH_SIZE, \n",
    "        shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "VxmewaUZTeOu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "0xaEJVazSyyz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Loading pre-trained weights\n",
      "[INFO]: Fine-tuning all layers...\n",
      "Loading trained model weights...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OSM\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\OSM\\AppData\\Roaming\\Python\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model().to(device)\n",
    "\n",
    "checkpoint = torch.load(MODEL_DIR, map_location=device)\n",
    "print('Loading trained model weights...')\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "RpKkOYMEUc55"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6fe12a7b5a14873ad5b33042d44eaed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/74 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image 10012 is unclassified with score: 0.3290358781814575\n",
      "Image 10024 is unclassified with score: 0.47946202754974365\n",
      "Image 1023 is unclassified with score: 0.4992971122264862\n",
      "Image 1035 is unclassified with score: 0.4001902639865875\n",
      "Image 1137 is unclassified with score: 0.443750262260437\n",
      "Image 1152 is unclassified with score: 0.4669169783592224\n",
      "Image 1190 is unclassified with score: 0.33299022912979126\n",
      "Image 1217 is unclassified with score: 0.4083831012248993\n",
      "Image 1259 is unclassified with score: 0.44746100902557373\n",
      "Image 1329 is unclassified with score: 0.45257261395454407\n",
      "Image 1335 is unclassified with score: 0.4619213938713074\n",
      "Image 1370 is unclassified with score: 0.41854190826416016\n",
      "Image 1469 is unclassified with score: 0.45848095417022705\n",
      "Image 1515 is unclassified with score: 0.39781078696250916\n",
      "Image 1548 is unclassified with score: 0.40578746795654297\n",
      "Image 1556 is unclassified with score: 0.40597692131996155\n",
      "Image 1660 is unclassified with score: 0.43530645966529846\n",
      "Image 167 is unclassified with score: 0.4260893166065216\n",
      "Image 1703 is unclassified with score: 0.36061379313468933\n",
      "Image 1721 is unclassified with score: 0.4753585755825043\n",
      "Image 1788 is unclassified with score: 0.4348227381706238\n",
      "Image 1866 is unclassified with score: 0.2761465907096863\n",
      "Image 1917 is unclassified with score: 0.4926176071166992\n",
      "Image 2065 is unclassified with score: 0.4001847505569458\n",
      "Image 2199 is unclassified with score: 0.49202147126197815\n",
      "Image 2345 is unclassified with score: 0.4292697012424469\n",
      "Image 2486 is unclassified with score: 0.4433968961238861\n",
      "Image 2514 is unclassified with score: 0.32953304052352905\n",
      "Image 2557 is unclassified with score: 0.4826585650444031\n",
      "Image 2623 is unclassified with score: 0.3753288686275482\n",
      "Image 2633 is unclassified with score: 0.47549012303352356\n",
      "Image 2772 is unclassified with score: 0.4412350356578827\n",
      "Image 2777 is unclassified with score: 0.4557666778564453\n",
      "Image 2838 is unclassified with score: 0.32711106538772583\n",
      "Image 3133 is unclassified with score: 0.3890225291252136\n",
      "Image 3198 is unclassified with score: 0.45831313729286194\n",
      "Image 3233 is unclassified with score: 0.48136475682258606\n",
      "Image 3283 is unclassified with score: 0.40928468108177185\n",
      "Image 3323 is unclassified with score: 0.4056966304779053\n",
      "Image 3436 is unclassified with score: 0.40872544050216675\n",
      "Image 3511 is unclassified with score: 0.485708087682724\n",
      "Image 3521 is unclassified with score: 0.4905243515968323\n",
      "Image 3558 is unclassified with score: 0.3634793758392334\n",
      "Image 3645 is unclassified with score: 0.4296394884586334\n",
      "Image 3652 is unclassified with score: 0.45625635981559753\n",
      "Image 3713 is unclassified with score: 0.451752245426178\n",
      "Image 3771 is unclassified with score: 0.47756049036979675\n",
      "Image 3789 is unclassified with score: 0.3495516777038574\n",
      "Image 3810 is unclassified with score: 0.44682905077934265\n",
      "Image 3821 is unclassified with score: 0.4886476993560791\n",
      "Image 391 is unclassified with score: 0.4676744341850281\n",
      "Image 4104 is unclassified with score: 0.4445554316043854\n",
      "Image 4140 is unclassified with score: 0.47826722264289856\n",
      "Image 418 is unclassified with score: 0.49784982204437256\n",
      "Image 4458 is unclassified with score: 0.45747193694114685\n",
      "Image 4466 is unclassified with score: 0.4425410330295563\n",
      "Image 4478 is unclassified with score: 0.35442790389060974\n",
      "Image 4573 is unclassified with score: 0.333978533744812\n",
      "Image 4615 is unclassified with score: 0.32964736223220825\n",
      "Image 502 is unclassified with score: 0.4702484607696533\n",
      "Image 53 is unclassified with score: 0.48709285259246826\n",
      "Image 566 is unclassified with score: 0.4057876467704773\n",
      "Image 610 is unclassified with score: 0.3958717882633209\n",
      "Image 767 is unclassified with score: 0.31907787919044495\n",
      "Image 797 is unclassified with score: 0.40597692131996155\n",
      "Image 815 is unclassified with score: 0.46683186292648315\n",
      "Image 957 is unclassified with score: 0.49574586749076843\n"
     ]
    }
   ],
   "source": [
    "ids = list()\n",
    "classes = list()\n",
    "threshold = 0.5\n",
    "\n",
    "with torch.no_grad():\n",
    "    for ( inputs, labels ) in tqdm(test_loader):\n",
    "        model.eval()\n",
    "        \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        scores, predicted = torch.max(outputs.data, 1)\n",
    "        \n",
    "        for i in range(len(scores)):\n",
    "            if scores[i].item() < threshold:\n",
    "                print(f\"Image {labels[i].item()} is unclassified with score:\", scores[i].item())\n",
    "                predicted[i] = 8 # assign spam class to the prediction\n",
    "            \n",
    "        classes.extend(predicted.cpu().numpy())\n",
    "        ids.extend(labels.cpu().numpy())\n",
    "\n",
    "should_be = []\n",
    "for i in range(len(ids)):\n",
    "    target = 1\n",
    "    # anything in `test` should not be spam  except ids > 10000\n",
    "    if ids[i] > 10000 :\n",
    "        target = 0\n",
    "        \n",
    "    if classes[i] == 8 :\n",
    "        classes[i] = 0\n",
    "    else :\n",
    "        classes[i] = 1\n",
    "    should_be.append(target)\n",
    "\n",
    "        \n",
    "df = pd.DataFrame({'ID': ids, 'class': classes})\n",
    "df.to_csv(SUBMISSION, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  22    5]\n",
      " [ 165 4483]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "# Calculate confusion matrix\n",
    "cm = confusion_matrix(should_be, classes)\n",
    "\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMN0fvNSQowt4d16LzdVhlK",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
